# -*- coding: utf-8 -*-
"""Untitled117.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1joPplkP9X3p1V6dywTAQ9Ocayc-Pu0EA
"""

import pandas as pd
import numpy as np
import os
import glob
import math
from collections import defaultdict, Counter
import re
import json

# ===================== Global Constants (for demonstration) =====================
# In a real script, these would be defined in a config file or as command-line arguments.
INPUT_ROOT = "."
TIME_COL = "ms"
TAIL_MS = 100
ANCHOR_MS = 250
ANCHOR_HALF_MS = 100
MAD_CUTOFF = 3.0
MIN_GAZE_SAMPLES = 3
SMOOTH_K = 0.5
ALPHA_LEXICON = 0.5
SIGMA_X_SCALE = 1.0
SIGMA_Y_SCALE = 1.0
LM_PREFIX_LAM = 1.0
CONTEXT_BONUS = 0.5
DIR_BONUS = 1.0
HAND_R_DEFAULT = 0.3
HAND_FLOOR_DEF = 0.1
USER_SCALE_GRID = [0.8, 1.0, 1.2]
HAND_R_GRID_USER = [0.2, 0.3, 0.4]
HAND_F_GRID_USER = [0.05, 0.1, 0.15]
TEMP_GRID = [0.8, 1.0, 1.2, 1.5, 2.0]
K_NEAR = 5
LM_TOPM = 3
STAGE1_HAND_R = 0.2
PREV_RING_R = 0.2
PREV_RING_K = 3
LEARNING_RATE = 0.1
MIN_USER_EVENTS = 5
DISTANCE_DECAY = 1.0
FINGERTIP_STEMS = ['Left_Hand_IndexTip', 'Right_Hand_IndexTip'] # Example stems
VALID_KEYS_PATTERN = re.compile(r'Key_([A-Z])_X')
EYE_QUALITY_WEIGHT = True
USE_BOTH_EYES_AVG = True
PREFER_LEFT_EYE = False
USE_RIGHT_EYE_IF_AVAILABLE = False
USE_LEFT_EYE_AS_FALLBACK = True
GAZE_QUALITY_THRESH = 0.5
LM_TRANS_W_BY_LEN = {0: 0.1, 1: 0.2, 2: 0.5, 3: 0.8}
LM_TRANS_W_MAX = 1.0
STRICT_PREFIX_AT = 2

# ===================== Helper Functions (provided from previous turns) =====================
def ensure_ms_timestamp(df, time_col):
    if df[time_col].iloc[0] > 10**12: df[time_col] /= 1000
    return df

def event_press_time(df):
    if TIME_COL in df.columns:
        return float(df[TIME_COL].median())
    return None

def slice_tail_window(df, press_t, tail_ms):
    return df[(df[TIME_COL] >= press_t - tail_ms) & (df[TIME_COL] < press_t)]

def slice_anchor_window(df, press_t, anchor_ms, half_ms):
    t_start = press_t - anchor_ms
    return df[(df[TIME_COL] >= t_start - half_ms) & (df[TIME_COL] < t_start + half_ms)]

def available_key_columns(df_columns):
    keys = {}
    for col in df_columns:
        m = VALID_KEYS_PATTERN.match(col)
        if m:
            ch = m.group(1)
            ycol = f"Key_{ch}_Y"
            if ycol in df_columns:
                keys[ch] = (col, ycol)
    return keys

def centers_from_window(df_window, key_cols_map):
    centers = {}
    for ch, (xc, yc) in key_cols_map.items():
        if xc in df_window.columns and yc in df_window.columns:
            x_vals = df_window[xc].astype(float).dropna()
            y_vals = df_window[yc].astype(float).dropna()
            if len(x_vals)>0 and len(y_vals)>0:
                x = float(x_vals.median()); y = float(y_vals.median())
                if not (np.isnan(x) or np.isnan(y)):
                    centers[ch] = (x, y)
    return centers

def normalize_layout(centers, gaze_xy):
    if not centers:
        return centers, gaze_xy, 1.0, np.zeros(2)
    pts = np.array(list(centers.values()))
    centroid = pts.mean(axis=0)
    dists = []
    for i in range(len(pts)):
        di = np.sqrt(((pts - pts[i])**2).sum(axis=1))
        di = di[di>0]
        if len(di):
            sorted_di = np.sort(di)
            dists.extend(sorted_di[:min(3, len(sorted_di))])
    spacing = float(np.median(dists)) if dists else 1.0
    centers_n = {k: ((v[0]-centroid[0])/spacing, (v[1]-centroid[1])/spacing) for k,v in centers.items()}
    gaze_n    = (gaze_xy - centroid)/spacing if gaze_xy.size else gaze_xy
    return centers_n, gaze_n, spacing, centroid

def last_valid_fingertips(df_window):
    if df_window.empty: return {}
    tail = df_window.tail(min(5, len(df_window)))
    tips = {}
    for stem in FINGERTIP_STEMS:
        xcol, ycol = f"{stem}_X", f"{stem}_Y"
        if xcol in tail.columns and ycol in tail.columns:
            x_vals = tail[xcol].astype(float).dropna()
            y_vals = tail[ycol].astype(float).dropna()
            if len(x_vals)>0 and len(y_vals)>0:
                x = float(x_vals.median()); y = float(y_vals.median())
                if not (np.isnan(x) or np.isnan(y)):
                    tips[stem] = (x, y)
    return tips

def normalize_points_dict(points_dict, centroid, spacing):
    return {k: ((v[0]-centroid[0])/spacing, (v[1]-centroid[1])/spacing) for k,v in points_dict.items()}

def detect_active_finger(fingertips_n, centers_n):
    best_name, best_dist = None, math.inf
    for name, xy in fingertips_n.items():
        if centers_n:
            dmin = min(np.hypot(xy[0]-c[0], xy[1]-c[1]) for c in centers_n.values())
            finger_bonus = 0.1 if 'Index' in name else 0.0
            adjusted = dmin - finger_bonus
            if adjusted < best_dist:
                best_name, best_dist = name, adjusted
    return best_name, best_dist

def time_weights_centered(gaze_ts, center_t, half_ms, qualities=None):
    if gaze_ts is None or gaze_ts.size == 0 or half_ms == 0: return None
    t_rel = np.abs(gaze_ts - center_t)
    weights = np.exp(-t_rel / half_ms)
    if qualities is not None and len(qualities) == len(weights):
        weights *= qualities
    return weights

def compute_tracking_quality(hit_series, x_series, y_series):
    # A simplified placeholder for quality
    hits = hit_series.astype(bool).sum()
    total = len(hit_series)
    return hits / total if total > 0 else 0.0

def _weighted_gaze_mean(ev):
    g = ev['gaze']
    if g.shape[0]==0: return None
    w = time_weights_centered(ev.get('gaze_ts'), ev.get('gaze_center'), ev.get('gaze_half'), ev.get('gaze_qualities'))
    if w is None or len(w)!=len(g): w=np.ones(g.shape[0])
    return (g * w[:,None]).sum(axis=0)/max(w.sum(),1e-6)

def posterior_from_logs(logs, temp=1.0):
    if not logs: return {}
    keys = list(logs.keys())
    vals = np.array([logs[k] for k in keys], dtype=float)/max(temp,1e-6)
    m = np.max(vals); p = np.exp(vals-m); p = p/(np.sum(p) if np.sum(p)>0 else 1.0)
    return {k: float(v) for k,v in zip(keys,p)}

def mix_log_probs(d1, d2, alpha=ALPHA_LEXICON, default_logp=-12.0):
    keys = set(d1.keys()) | set(d2.keys())
    out={}
    for k in keys:
        l1 = d1.get(k, default_logp)
        l2 = d2.get(k, default_logp)
        m = l1 if l1>l2 else l2
        out[k] = m + math.log(alpha*math.exp(l1-m) + (1-alpha)*math.exp(l2-m))
    return out

# ===================== NEW: Gaze-Hand Synergy Model =====================
def learn_gaze_hand_synergy_model(events):
    """Learns the mean and standard deviation of the gaze-hand distance."""
    distances = []
    for ev in events:
        if ev.get('active_tip_xy') is not None:
            gm = _weighted_gaze_mean(ev)
            if gm is not None:
                dist = np.hypot(gm[0] - ev['active_tip_xy'][0], gm[1] - ev['active_tip_xy'][1])
                distances.append(dist)
    if not distances:
        return {'mean': 0.0, 'std': 1.0}

    dists = np.array(distances)
    return {'mean': float(np.mean(dists)), 'std': float(np.std(dists))}

def gaze_hand_synergy_score(ev, synergy_model):
    """Calculates the log-likelihood of the gaze-hand distance."""
    if ev.get('active_tip_xy') is None:
        return 0.0

    gm = _weighted_gaze_mean(ev)
    if gm is None:
        return 0.0

    dist = np.hypot(gm[0] - ev['active_tip_xy'][0], gm[1] - ev['active_tip_xy'][1])
    mean = synergy_model['mean']
    std = synergy_model['std']

    if std <= 1e-6:
        return -10.0 # Assign a penalty if std is too small

    logp = -0.5 * ((dist - mean) / std)**2 - 0.5 * np.log(2 * np.pi * std**2)
    return float(logp)

# ===================== Gaze processing (from previous turn) =====================
def pick_gaze_xy_with_time(df_window, time_col=TIME_COL):
    xs, ys, ts, quals = [], [], [], []
    cols = set(df_window.columns)
    has_R = {'RightGazeHit','RightGazeHitPosition_X','RightGazeHitPosition_Y'} <= cols
    has_L = {'LeftGazeHit','LeftGazeHitPosition_X','LeftGazeHitPosition_Y'} <= cols

    if EYE_QUALITY_WEIGHT and has_L and has_R:
        lq = compute_tracking_quality(df_window['LeftGazeHit'], df_window['LeftGazeHitPosition_X'], df_window['LeftGazeHitPosition_Y'])
        rq = compute_tracking_quality(df_window['RightGazeHit'], df_window['RightGazeHitPosition_X'], df_window['RightGazeHitPosition_Y'])
    else:
        lq = rq = 0.5

    for _, row in df_window.iterrows():
        gx = gy = None; chosen=False; q=0.0
        if has_L and has_R and bool(row['LeftGazeHit']) and bool(row['RightGazeHit']) and USE_BOTH_EYES_AVG:
            if EYE_QUALITY_WEIGHT:
                tot = lq + rq
                wl = lq / tot if tot>0 else 0.5
                wr = rq / tot if tot>0 else 0.5
            else:
                wl = wr = 0.5
            gx = wl*float(row['LeftGazeHitPosition_X']) + wr*float(row['RightGazeHitPosition_X'])
            gy = wl*float(row['LeftGazeHitPosition_Y']) + wr*float(row['RightGazeHitPosition_Y'])
            q = max(lq, rq); chosen=True
        elif has_L and bool(row['LeftGazeHit']) and PREFER_LEFT_EYE:
            gx, gy = float(row['LeftGazeHitPosition_X']), float(row['LeftGazeHitPosition_Y']); q=lq; chosen=True
        elif has_R and bool(row['RightGazeHit']) and USE_RIGHT_EYE_IF_AVAILABLE:
            gx, gy = float(row['RightGazeHitPosition_X']), float(row['RightGazeHitPosition_Y']); q=rq; chosen=True
        elif has_L and bool(row['LeftGazeHit']) and USE_LEFT_EYE_AS_FALLBACK:
            gx, gy = float(row['LeftGazeHitPosition_X']), float(row['LeftGazeHitPosition_Y']); q=lq; chosen=True

        if chosen and not (np.isnan(gx) or np.isnan(gy)) and q >= GAZE_QUALITY_THRESH:
            xs.append(gx); ys.append(gy); ts.append(float(row[time_col]) if time_col in df_window.columns else np.nan); quals.append(q)

    xy = np.column_stack([xs, ys]) if xs else np.empty((0,2))
    ts = np.array(ts, dtype=float) if ts else np.array([])
    quals = np.array(quals, dtype=float) if quals else np.array([])
    return xy, ts, quals

def filter_gaze_outliers(gaze_xy, gaze_qualities=None, mad_k=MAD_CUTOFF):
    if gaze_xy.shape[0] < 2:
        keep = np.arange(gaze_xy.shape[0])
        return gaze_xy, keep, (gaze_qualities if gaze_qualities is not None else np.array([]))
    med = np.median(gaze_xy, axis=0)
    r = np.linalg.norm(gaze_xy - med, axis=1)
    r_med = np.median(r)
    mad = np.median(np.abs(r - r_med))
    if mad <= 1e-9:
        keep_mask = np.ones_like(r, dtype=bool)
    else:
        z = 0.6745 * (r - r_med) / mad
        keep_mask = np.abs(z) <= mad_k
    keep_idx = np.where(keep_mask)[0]
    fq = gaze_qualities[keep_idx] if gaze_qualities is not None and len(gaze_qualities)==len(gaze_xy) else np.array([])
    return gaze_xy[keep_idx], keep_idx, fq

def align_gaze_to_keyboard(gaze_xy, centers):
    if gaze_xy.shape[0] < 1 or not centers:
        return gaze_xy
    keyboard_points = np.array(list(centers.values()))
    keyboard_centroid = keyboard_points.mean(axis=0)
    gaze_centroid = gaze_xy.mean(axis=0)
    return gaze_xy + (keyboard_centroid - gaze_centroid)

# ===================== Scoring (Modified to add synergy) =====================
def loglike_gaze_given_key(ev, key, mu=None, sigma=None):
    g = ev['gaze']
    if g.shape[0]==0: return -np.inf
    ctr = np.array(ev['centers'][key])
    mk = PERKEY_GAZE.get(key, {'mu':np.zeros(2), 'sigma':np.array([0.35,0.20])})
    mu_k = mk['mu'] if mu is None else mu
    sx, sy = mk['sigma'] if sigma is None else sigma
    w = time_weights_centered(ev.get('gaze_ts'), ev.get('gaze_center'), ev.get('gaze_half'), ev.get('gaze_qualities'))
    if w is None or len(w)!=len(g): w=np.ones(g.shape[0])
    dx = (g[:,0] - (ctr[0] + mu_k[0]))/max(sx,1e-6)
    dy = (g[:,1] - (ctr[1] + mu_k[1]))/max(sy,1e-6)
    ll = -0.5*(dx*dx + dy*dy) - 0.5*np.log(2*np.pi*max(sx,1e-6)*max(sy,1e-6))
    return float(np.sum(w*ll))

def lm_bonus_prefix(ev, key, lam=LM_PREFIX_LAM, default_logp=-8.0):
    prefix = ev.get('prefix','')
    d = PREFIX_LOGP if isinstance(PREFIX_LOGP, dict) else {}
    return lam * float(d.get((prefix, key), default_logp))

def lm_bonus_context(ev, key, beta=CONTEXT_BONUS, default_logp=-10.0):
    if not isinstance(CONTEXT_LOGP, dict) or not CONTEXT_LOGP: return 0.0
    ctx = ev.get('context','')
    if not ctx: return 0.0
    return beta * float(CONTEXT_LOGP.get((ctx, key), default_logp))

def directional_bonus(ev, key, beta=DIR_BONUS):
    prev = ev.get('prev'); centers = ev['centers']
    if prev not in centers or key not in centers: return 0.0
    g = ev['gaze']; if_empty = (g.shape[0]==0)
    if if_empty: return 0.0
    w = time_weights_centered(ev.get('gaze_ts'), ev.get('gaze_center'), ev.get('gaze_half'), ev.get('gaze_qualities'))
    if w is None or len(w)!=len(g): w=np.ones(g.shape[0])
    gm = (g * w[:,None]).sum(axis=0)/max(w.sum(),1e-6)
    pv = np.array(centers[prev]); kv = np.array(centers[key])
    v1 = gm - pv; v2 = kv - pv
    n1 = np.linalg.norm(v1); n2 = np.linalg.norm(v2)
    if n1 < 1e-6 or n2 < 1e-6: return 0.0
    cos = float(np.dot(v1/n1, v2/n2))
    return beta * max(0.0, cos)

def hand_prior_weight(key_xy, tip_xy, R, floor):
    if tip_xy is None: return 1.0
    d = float(np.hypot(tip_xy[0]-key_xy[0], tip_xy[1]-key_xy[1]))
    return max(floor, math.exp(-(d/max(R,1e-6))**2))

def score_event(ev, user_scale=1.0, user_mu=None, use_lm=True, use_hand=True,
                hand_R=HAND_R_DEFAULT, hand_floor=HAND_FLOOR_DEF, cand=None, synergy_model=None):
    cand = cand if cand else list(ev['centers'].keys())
    log_scores={}
    mk_mu = PERKEY_GAZE
    gm = _weighted_gaze_mean(ev)

    g_obs = ev['gaze']
    obs_std = np.std(g_obs, axis=0) if g_obs.shape[0] >= 2 else np.array([1.0,1.0])
    ev_scale = float(np.clip(np.mean(obs_std), 0.8, 1.5))

    # NEW: Add synergy score for this event
    synergy_ll = gaze_hand_synergy_score(ev, synergy_model)

    for k in cand:
        base = mk_mu.get(k, {'mu':np.zeros(2), 'sigma':np.array([0.35,0.20])})
        mu_k = base['mu'].copy()
        if user_mu and k in user_mu and user_mu[k][2] >= MIN_USER_EVENTS:
            sx, sy, n = user_mu[k]
            mu_k += np.array([sx, sy])/max(n,1)
        sigma_k = base['sigma'] * (user_scale * ev_scale)
        ll = loglike_gaze_given_key(ev, k, mu=mu_k, sigma=sigma_k)

        if gm is not None:
            cx, cy = ev['centers'][k]
            dist2 = (gm[0]-cx)**2 + (gm[1]-cy)**2
            ll -= DISTANCE_DECAY * dist2

        if use_lm:
            prev = ev.get('prev','^')
            ll += BGRAM_LOGP.get((prev, k), 0.0)
            ll += lm_bonus_prefix(ev, k, lam=LM_PREFIX_LAM)
            ll += lm_bonus_context(ev, k, beta=CONTEXT_BONUS)

        if use_hand:
            ll += math.log(hand_prior_weight(ev['centers'][k], ev.get('active_tip_xy',None), hand_R, hand_floor))

        ll += directional_bonus(ev, k, beta=DIR_BONUS)
        ll += synergy_ll # ADD THE NEW SYNERGY SCORE

        log_scores[k]=ll

    ranked = sorted(log_scores.items(), key=lambda x:x[1], reverse=True)
    return ranked, log_scores

# ===================== Build events (Modified) =====================
def build_events_and_lms(raw_df):
    print("Building events...")
    events = []; key_cols_cache = None

    raw_df['PressedLetter'] = raw_df['PressedLetter'].astype(str).str.strip().str.upper()
    raw_df['CurrentLetter'] = raw_df['CurrentLetter'].astype(str).str.strip().str.upper()
    raw_df = raw_df[(raw_df['PressedLetter'].str.len()==1) & (raw_df['PressedLetter'].str.isalpha())]
    raw_df = raw_df[raw_df['PressedLetter'] == raw_df['CurrentLetter']]
    raw_df = raw_df.sort_values(['ParticipantID','TrialNumber','PhraseIndex','LetterIndex', TIME_COL], kind='mergesort')

    for keys, df_ev in raw_df.groupby(['ParticipantID','TrialNumber','PhraseIndex','LetterIndex','PressedLetter'], sort=False):
        pid, tr, phr, idx, label = keys
        t_press = event_press_time(df_ev)
        if t_press is None: continue

        win_tail = slice_tail_window(df_ev, t_press, TAIL_MS)
        win_gaze = slice_anchor_window(df_ev, t_press, ANCHOR_MS, ANCHOR_HALF_MS)
        if win_gaze.empty or win_tail.empty: continue

        gaze_xy_raw, gaze_ts, gaze_qualities = pick_gaze_xy_with_time(win_gaze)

        key_cols_map = available_key_columns(win_tail.columns) if key_cols_cache is None else key_cols_cache
        if key_cols_cache is None: key_cols_cache = key_cols_map
        centers = centers_from_window(win_tail, key_cols_map)
        if label not in centers: continue

        gaze_xy_aligned = align_gaze_to_keyboard(gaze_xy_raw, centers)
        centers_n, gaze_n, spacing, centroid = normalize_layout(centers, gaze_xy_aligned)
        gaze_n, kept_idx, filtered_qualities = filter_gaze_outliers(gaze_n, gaze_qualities, MAD_CUTOFF)
        if gaze_n.shape[0] < MIN_GAZE_SAMPLES: continue
        if gaze_ts.size: gaze_ts = gaze_ts[kept_idx]

        tips_raw = last_valid_fingertips(win_tail)
        tips_n = normalize_points_dict(tips_raw, centroid, spacing) if tips_raw else {}
        active_tip_name, active_tip_dist = detect_active_finger(tips_n, centers_n) if tips_n else (None, None)
        active_tip_xy = tips_n.get(active_tip_name, None) if tips_n else None

        def phrase_alpha_maps_row(grp):
            ph = str(grp['Phrase'].dropna().astype(str).iloc[-1]) if 'Phrase' in grp.columns and not grp['Phrase'].dropna().empty else ''
            alpha_prev={}; alpha_prefix={}; alpha_ctx={}
            prev_char='^'; current_word=''; word_hist=[]; i=0
            for ch in ph:
                if ch.isalpha():
                    alpha_prev[i]=prev_char; alpha_prefix[i]=current_word; alpha_ctx[i]=' '.join(word_hist[-2:])
                    prev_char=ch.upper(); current_word+=ch.upper(); i+=1
                else:
                    if current_word: word_hist.append(current_word)
                    prev_char='^'; current_word=''
            return alpha_prev, alpha_prefix, alpha_ctx

        pmap_prev, pmap_pref, pmap_ctx = phrase_alpha_maps_row(df_ev)
        prev = pmap_prev.get(int(idx), '^')
        prefix = pmap_pref.get(int(idx), '')
        ctx = pmap_ctx.get(int(idx), '')

        events.append({
            'pid': pid, 'trial': tr, 'phrase': phr, 'lidx': int(idx), 'label': label,
            'press_time': t_press,
            'gaze': gaze_n, 'gaze_ts': gaze_ts, 'gaze_qualities': filtered_qualities,
            'gaze_center': t_press - ANCHOR_MS, 'gaze_half': ANCHOR_HALF_MS,
            'centers': centers_n,
            'active_tip': active_tip_name, 'active_tip_xy': active_tip_xy, 'active_tip_dist': active_tip_dist,
            'prev': (prev if isinstance(prev,str) and len(prev)==1 and prev.isalpha() else '^'),
            'prefix': prefix, 'context': ctx,
            'anchor_mode': 'pre_press'
        })
    if not events: raise RuntimeError("No valid events after filtering.")
    print(f"Events ready: {len(events)}")
    return events

# ===================== Main Execution Block =====================
if __name__ == '__main__':
    print("Scanning CSVs under:", INPUT_ROOT)
    csv_files = glob.glob(os.path.join(INPUT_ROOT, "**", "*.csv"), recursive=True)
    if not csv_files: raise RuntimeError(f"No CSV files under {INPUT_ROOT}.")

    frames=[]
    for fp in csv_files:
        try:
            df = pd.read_csv(fp)
            df = ensure_ms_timestamp(df, TIME_COL)
            df['__source__'] = os.path.basename(fp)
            frames.append(df)
        except Exception as e:
            print(f"Skip {fp}: {e}")
    raw = pd.concat(frames, ignore_index=True)

    events = build_events_and_lms(raw.copy())

    # NEW: Learn the gaze-hand synergy model parameters
    SYNERGY_MODEL = learn_gaze_hand_synergy_model(events)
    print(f"Gaze-Hand Synergy Model learned: Mean={SYNERGY_MODEL['mean']:.3f}, Std={SYNERGY_MODEL['std']:.3f}")

    # The rest of the pipeline functions would be here, but they need to be modified
    # to accept and use the SYNERGY_MODEL parameter in their calls to score_event.
    # For example:
    # res = eval_with_user_tuning(events, synergy_model=SYNERGY_MODEL)
    # gate_df, _, _, _ = eval_conf_gating_p1(events, ..., synergy_model=SYNERGY_MODEL)
    # vit_acc, vit_n = eval_viterbi(events, ..., synergy_model=SYNERGY_MODEL)

    # As the full script is too long, these are just illustrative calls.
    # The key change is adding the synergy_model parameter to all relevant functions.